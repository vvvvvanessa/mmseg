import os.path
from mmengine import Config
from mmengine.runner import Runner
from mmseg.registry import DATASETS  # âœ… è¿™æ˜¯å®˜æ–¹æ¨èæ–¹å¼
from mmengine.registry import MODELS

import datasets.AsphaltDataset
import cv2
import numpy as np
import torch

#
# config_file = 'pspnet_r50-d8_4xb2-40k_cityscapes-512x1024.py'
# checkpoint_file = 'pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'
#
# # æ ¹æ®é…ç½®æ–‡ä»¶å’Œæ¨¡å‹æ–‡ä»¶å»ºç«‹æ¨¡å‹
# model = init_model(config_file, checkpoint_file, device='cuda:0')
#
# # åœ¨å•å¼ å›¾åƒä¸Šæµ‹è¯•å¹¶å¯è§†åŒ–
# img = 'demo/demo.JPG'  # or img = mmcv.imread(img), è¿™æ ·ä»…éœ€ä¸‹è½½ä¸€æ¬¡
# result = inference_model(model, img)
# # åœ¨æ–°çš„çª—å£å¯è§†åŒ–ç»“æœ
# show_result_pyplot(model, img, result, show=True)
# # æˆ–è€…å°†å¯è§†åŒ–ç»“æœä¿å­˜åˆ°å›¾åƒæ–‡ä»¶å¤¹ä¸­
# # æ‚¨å¯ä»¥ä¿®æ”¹åˆ†å‰² map çš„é€æ˜åº¦ (0, 1].
# show_result_pyplot(model, img, result, show=True, out_file='result.jpg', opacity=0.5)
# # åœ¨ä¸€æ®µè§†é¢‘ä¸Šæµ‹è¯•å¹¶å¯è§†åŒ–åˆ†å‰²ç»“æœ
# # video = mmcv.VideoReader('video.mp4')
# # for frame in video:
# #    result = inference_model(model, frame)
# #    show_result_pyplot(model, frame, result, wait_time=1)

if __name__ == "__main__":
    # åŠ è½½é…ç½®æ–‡ä»¶
    config_path = 'configs/my_config.py'
    cfg = Config.fromfile(config_path)

    # æ„å»º Runner
    runner = Runner.from_cfg(cfg)

    # ä¿å­˜åŸå§‹çš„ train_step æ–¹æ³•ï¼ˆå¦‚æœåç»­éœ€è¦å‚è€ƒçœŸå®é€»è¾‘ï¼Œå¯ä¿ç•™ï¼‰
    orig_train_step = runner.model.train_step

    import torch


    def debug_train_step_dummy(self, data_batch, optim_wrapper):
        print("ğŸŸ¢ Debug train_step (dummy) called")
        print(f"data_batch keys: {data_batch.keys()}")
        inputs = data_batch['inputs']
        print(f"inputs type: {type(inputs)}")
        print(f"Number of samples: {len(inputs)}")
        if isinstance(inputs, list) and len(inputs) > 0:
            print(f"First input shape: {inputs[0].shape}")
        data_samples = data_batch['data_samples']
        print(f"data_samples type: {type(data_samples)}")
        print(f"First gt_sem_seg shape: {data_samples[0].gt_sem_seg.data.shape}")

        # è·å–æ¨¡å‹è®¾å¤‡
        device = next(self.parameters()).device

        # æ„é€ å¹³å±•çš„ dummy loss å­—å…¸ï¼Œæ¯ä¸ªå€¼ç›´æ¥æ˜¯ä¸€ä¸ª scalar tensor
        loss_seg = torch.tensor(0.0, device=device)
        loss_aux = torch.tensor(0.0, device=device)
        dummy_loss = {
            'loss_seg': loss_seg,
            'loss_aux': loss_aux,
            'loss': loss_seg + loss_aux  # é€šå¸¸éœ€è¦æä¾›æ€» loss
        }

        print("==> Return dummy loss, skipping forward/backward")
        return dummy_loss


    # ä½¿ç”¨ dummy loss çš„ train_step æ›¿æ¢åŸå§‹æ–¹æ³•
    # runner.model.train_step = debug_train_step_dummy.__get__(runner.model, type(runner.model))

    # è¾“å‡ºæ¨¡å‹æ‰€åœ¨è®¾å¤‡ï¼ˆä»æ¨¡å‹å‚æ•°ä¸­è·å–è®¾å¤‡ä¿¡æ¯ï¼‰
    model_device = next(runner.model.parameters()).device
    print("Model device:", model_device)

    # å¼€å§‹è®­ç»ƒ
    runner.train()